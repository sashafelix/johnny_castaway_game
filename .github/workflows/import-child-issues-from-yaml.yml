name: Import Child Issues from YAML

on:
  workflow_dispatch:
    inputs:
      yaml_path:
        description: "Path to YAML (e.g. ops/issues/m1-child-issues.yml)"
        required: true
        default: "ops/issues/m1-child-issues.yml"
      dry_run:
        description: "If true: do not create anything, only print what would happen"
        required: true
        default: "true"
        type: choice
        options: ["true", "false"]
      update_epic_checklists:
        description: "If true: link child issues into parent epic checklist (batched, robust matching)"
        required: true
        default: "true"
        type: choice
        options: ["true", "false"]
      max_existing_issue_pages:
        description: "How many pages (100/page) to scan for existing issue titles (reduce API calls)."
        required: true
        default: "5"

permissions:
  issues: write

concurrency:
  group: import-child-issues-from-yaml
  cancel-in-progress: false

jobs:
  import:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Debug workspace
        run: |
          echo "PWD: $(pwd)"
          ls -la ops/issues || true
          find . -maxdepth 6 -type f \( -name "*.yml" -o -name "*.yaml" \) -print

      - uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install js-yaml
        run: npm install js-yaml

      - name: Import child issues (or dry-run) + batch-update epic checklists
        uses: actions/github-script@v7
        env:
          YAML_PATH: ${{ inputs.yaml_path }}
          DRY_RUN: ${{ inputs.dry_run }}
          UPDATE_EPIC_CHECKLISTS: ${{ inputs.update_epic_checklists }}
          MAX_EXISTING_PAGES: ${{ inputs.max_existing_issue_pages }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require("fs");
            const path = require("path");
            const yaml = require("js-yaml");

            const yamlPathInput = (process.env.YAML_PATH || "").trim();
            const dryRun = ((process.env.DRY_RUN || "true").trim() === "true");
            const updateEpics = ((process.env.UPDATE_EPIC_CHECKLISTS || "true").trim() === "true");
            const maxExistingPages = parseInt((process.env.MAX_EXISTING_PAGES || "5").trim(), 10);

            core.info(`Inputs -> yaml_path="${yamlPathInput}", dry_run=${dryRun}, update_epic_checklists=${updateEpics}, max_existing_issue_pages=${maxExistingPages}`);

            if (!yamlPathInput) { core.setFailed('Input "yaml_path" is empty'); return; }

            const yamlPath = path.resolve(process.cwd(), yamlPathInput);
            core.info(`Resolved YAML path -> ${yamlPath}`);

            if (!fs.existsSync(yamlPath)) { core.setFailed(`YAML file not found: ${yamlPath}`); return; }

            const doc = yaml.load(fs.readFileSync(yamlPath, "utf8"));
            const milestoneNumber = doc.milestone_number;
            const milestoneTitle = doc.milestone;
            const items = doc.issues || [];

            if (!milestoneNumber && !milestoneTitle) {
              core.setFailed("YAML must include either 'milestone_number' or 'milestone'.");
              return;
            }

            // Resolve milestone (prefer number)
            let msNumber = milestoneNumber;
            let msTitleForLog = milestoneTitle || `(by number ${milestoneNumber})`;

            if (!msNumber) {
              const milestones = await github.paginate(github.rest.issues.listMilestones, {
                ...context.repo,
                state: "all",
                per_page: 100,
              });
              const ms = milestones.find(m => m.title === milestoneTitle);
              if (!ms) { core.setFailed(`Milestone not found (must match exactly): "${milestoneTitle}"`); return; }
              msNumber = ms.number;
              msTitleForLog = ms.title;
            }

            core.info(`Using milestone #${msNumber}: ${msTitleForLog}`);
            core.info(`Issues in YAML: ${items.length}`);

            // Cache existing issues by title -> number (works for "Skip (exists)" linking)
            const titleToNumber = new Map();
            if (!dryRun) {
              core.info(`Scanning existing issues (up to ${maxExistingPages} pages @ 100/page)...`);
              for (let page = 1; page <= maxExistingPages; page++) {
                const res = await github.rest.issues.listForRepo({
                  ...context.repo,
                  state: "all",
                  per_page: 100,
                  page,
                });
                for (const it of res.data) titleToNumber.set(it.title, it.number);
                if (res.data.length < 100) break;
              }
              core.info(`Cached ${titleToNumber.size} existing issues (title -> number).`);
            } else {
              core.info("DRY-RUN: skipping scan of existing issues to minimize API calls.");
            }

            // Cache epics by title
            const epicsByTitle = new Map();
            core.info("Fetching epics (label: type:epic)...");
            const epics = await github.paginate(github.rest.issues.listForRepo, {
              ...context.repo,
              state: "all",
              labels: "type:epic",
              per_page: 100,
            });
            for (const e of epics) epicsByTitle.set(e.title, e);
            core.info(`Cached ${epicsByTitle.size} epics (title -> issue).`);

            function mdChecklist(lines) {
              if (!lines || lines.length === 0) return "_(none)_";
              return lines.map(x => `- [ ] ${x}`).join("\n");
            }

            function buildBody(item, epicNumberOrNull) {
              const b = item.body || {};
              const out = [];

              if (item.type === "chore") {
                out.push(`## Chore type\n${b.chore_type || "tooling (scripts, CI, automation)"}\n`);
              }
              out.push(`## What\n${b.what || ""}\n`);
              out.push(`## Why\n${b.why || ""}\n`);
              out.push(`## Definition of Done\n${mdChecklist(b.definition_of_done || [])}\n`);
              out.push(`## System\n${b.system || ""}\n`);
              out.push(`## Priority\n${b.priority || ""}\n`);

              if (b.notes) out.push(`## Notes / links\n${b.notes}\n`);

              if (item.parent_epic) {
                if (epicNumberOrNull) out.push(`## Parent Epic\n- #${epicNumberOrNull}\n`);
                else out.push(`## Parent Epic\n- ${item.parent_epic}\n`);
              }

              out.push(`---\n**Area:** ${item.area || ""}  \n**Estimate:** ${item.estimate || ""}  \n**Risk:** ${item.risk || ""}\n`);
              return out.join("\n").trim() + "\n";
            }

            // Normalization helpers for robust checklist matching
            const TYPE_PREFIX_RE = /^(feat|feature|chore|bug|tech-debt|config)\s*:\s*/i;
            const ISSUE_REF_RE = /^#\d+\s+/;

            function normalizeText(s) {
              return (s || "")
                .replace(/\u00A0/g, " ")     // nbsp
                .replace(/\s+/g, " ")
                .trim();
            }

            function normalizeChecklistContent(lineContent) {
              // Remove issue ref and type prefix so we can match raw_title or title variants
              let t = normalizeText(lineContent);
              t = t.replace(ISSUE_REF_RE, "");
              t = t.replace(TYPE_PREFIX_RE, "");
              return t.trim();
            }

            function parseChecklistLine(line) {
              // Matches:
              // - [ ] text
              // * [x] text
              const m = line.match(/^\s*[-*]\s*\[\s*[ xX]?\s*\]\s*(.+?)\s*$/);
              return m ? m[1] : null;
            }

            function ensureChecklistSection(body) {
              const header = "## Child Issue Checklist";
              if (body.includes(header)) return body;
              return (body || "").trimEnd() + `\n\n${header}\n\n`;
            }

            function upsertChecklistLink(epicBody, rawTitle, fullTitle, issueNumber) {
              let body = ensureChecklistSection(epicBody || "");
              const lines = body.split("\n");

              const candidates = [];
              if (rawTitle) candidates.push(rawTitle);
              if (fullTitle) candidates.push(fullTitle);
              if (fullTitle) candidates.push(fullTitle.replace(TYPE_PREFIX_RE, "")); // without "feat:"
              const candidateNorms = candidates.map(c => normalizeChecklistContent(c));

              // Find best matching checklist line anywhere in body
              let foundIndex = -1;

              for (let i = 0; i < lines.length; i++) {
                const content = parseChecklistLine(lines[i]);
                if (!content) continue;

                const lineNorm = normalizeChecklistContent(content);
                if (candidateNorms.includes(lineNorm)) {
                  foundIndex = i;
                  break;
                }
              }

              const newLine = `- [ ] #${issueNumber} ${fullTitle}`;

              if (foundIndex >= 0) {
                // Replace exact matched line
                lines[foundIndex] = newLine;
                return { updatedBody: lines.join("\n"), action: "replaced" };
              }

              // Append under checklist header
              const headerIdx = lines.findIndex(l => l.trim() === "## Child Issue Checklist");
              if (headerIdx >= 0) {
                // Insert after header (skip possible blank line)
                let insertAt = headerIdx + 1;
                while (insertAt < lines.length && lines[insertAt].trim() === "") insertAt++;
                lines.splice(insertAt, 0, newLine);
                return { updatedBody: lines.join("\n"), action: "appended" };
              }

              // Fallback: append at end
              lines.push("", "## Child Issue Checklist", "", newLine);
              return { updatedBody: lines.join("\n"), action: "appended" };
            }

            // Batch updates: epicNumber -> { epic, body, pending: [{rawTitle,title,issueNumber}] }
            const epicBatches = new Map();

            function queueEpicUpdate(epic, rawTitle, title, issueNumber) {
              if (!updateEpics || !epic) return;
              const key = String(epic.number);
              if (!epicBatches.has(key)) {
                epicBatches.set(key, { epic, originalBody: epic.body || "", pending: [] });
              }
              epicBatches.get(key).pending.push({ rawTitle, title, issueNumber });
            }

            let wouldCreate = 0, created = 0, skipped = 0;

            for (const item of items) {
              const title = (item.title || "").trim();
              if (!title) continue;

              const epic = item.parent_epic ? epicsByTitle.get(item.parent_epic) : null;

              // Determine existing
              const existingNumber = (!dryRun && titleToNumber.has(title)) ? titleToNumber.get(title) : null;

              if (dryRun) {
                wouldCreate++;
                core.info(`[DRY-RUN] Would create: "${title}" | milestone #${msNumber} | labels=${JSON.stringify(item.labels || [])} | parent_epic=${epic ? "#" + epic.number : (item.parent_epic || "(none)")}`);
                continue;
              }

              let issueNumber = existingNumber;

              if (existingNumber) {
                skipped++;
                core.info(`Skip (exists): #${existingNumber} ${title}`);
              } else {
                const createdIssue = await github.rest.issues.create({
                  ...context.repo,
                  title,
                  body: buildBody(item, epic ? epic.number : null),
                  milestone: msNumber,
                  labels: item.labels || [],
                });
                issueNumber = createdIssue.data.number;
                created++;
                core.info(`Created #${issueNumber}: ${title}`);
                titleToNumber.set(title, issueNumber);
              }

              // Queue epic checklist linkage (even for skipped issues)
              queueEpicUpdate(epic, (item.raw_title || "").trim(), title, issueNumber);
            }

            if (dryRun) {
              core.info(`DRY-RUN complete. Would create: ${wouldCreate}`);
              return;
            }

            // Apply batched epic updates (one update per epic per run)
            if (updateEpics && epicBatches.size > 0) {
              core.info(`Applying batched epic checklist updates for ${epicBatches.size} epic(s)...`);

              for (const batch of epicBatches.values()) {
                let body = batch.originalBody || "";
                let changed = 0;

                for (const entry of batch.pending) {
                  const before = body;
                  const res = upsertChecklistLink(body, entry.rawTitle, entry.title, entry.issueNumber);
                  body = res.updatedBody;
                  if (body !== before) {
                    changed++;
                    core.info(`Epic #${batch.epic.number}: ${res.action} checklist -> #${entry.issueNumber} (${entry.title})`);
                  }
                }

                if (changed > 0) {
                  await github.rest.issues.update({
                    ...context.repo,
                    issue_number: batch.epic.number,
                    body,
                  });
                  core.info(`Updated epic #${batch.epic.number} (${batch.epic.title}) with ${changed} checklist link(s).`);
                } else {
                  core.info(`No epic changes needed for #${batch.epic.number} (${batch.epic.title}).`);
                }
              }
            }

            core.info(`Done. Created: ${created}, Skipped: ${skipped}`);
